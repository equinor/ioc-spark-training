{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# JOINS #"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import Row, DataFrame\n",
    "from pyspark import SparkContext, SparkConf\n",
    "# create entry points to spark\n",
    "try:\n",
    "    sc.stop()\n",
    "except:\n",
    "    pass\n",
    "from pyspark import SparkContext, SparkConf\n",
    "from pyspark.sql import SparkSession\n",
    "sc=SparkContext()\n",
    "spark = SparkSession(sparkContext=sc)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "row1 = Row(\"name\", \"pet\", \"count\")\n",
    "row2 = Row(\"name\", \"vehicle\", \"count\")\n",
    "\n",
    "df1 = sc.parallelize([\n",
    "    row1(\"Sue\", \"cat\", 16),\n",
    "    row1(\"Kim\", \"dog\", 1),    \n",
    "    row1(\"Bob\", \"fish\", 5),\n",
    "    row1(\"Libuse\", \"horse\", 1)\n",
    "    ]).toDF()\n",
    "\n",
    "df2 = sc.parallelize([\n",
    "    row2(\"Sue\", \"car\", 2),\n",
    "    row2(\"Kim\", \"car\", 1),    \n",
    "    row2(\"Bob\", \"bycicle\", 2),\n",
    "    row2(\"Ferdinand\", \"boat\", 1)\n",
    "    ]).toDF()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Inner join ###\n",
    "\n",
    "Merges rows that have a match in both dataframes and drops all others. This is the default type of join, so the how argument could be omitted here if you didn't wish to be explicit (being explicit is almost always better, however). We will merge on the entries in the name column, which you can see is the second argument in the method; this can also be a list if the merge should happen on more than one matching value:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+----+-----+-------+-----+\n",
      "|name| pet|count|vehicle|count|\n",
      "+----+----+-----+-------+-----+\n",
      "| Sue| cat|   16|    car|    2|\n",
      "| Bob|fish|    5|bycicle|    2|\n",
      "| Kim| dog|    1|    car|    1|\n",
      "+----+----+-----+-------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df1.join(df2, 'name', how='inner').show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Outer join ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1.join(df2, 'name', how='').show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Left join ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1.join(df2, 'name', how='').show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
